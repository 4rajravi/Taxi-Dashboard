services:
  # Apache Kafka (KRaft Mode)
  kafka-broker:
    image: apache/kafka:4.0.0
    container_name: kafka-broker
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://kafka-broker:9092,CONTROLLER://kafka-broker:9093,EXTERNAL://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,EXTERNAL://localhost:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-broker:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS}
    ports:
      - "9094:9094"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "./opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server kafka-broker:9092 > /dev/null 2>&1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "2g"
        reservations:
          cpus: "1"
          memory: "1gb"

  # Apache Kafka Init Container (Create Topics)
  kafka-init:
    image: apache/kafka:4.0.0
    container_name: kafka-init
    entrypoint: ["/bin/bash", "/scripts/create-kafka-topics.sh"]
    environment:
      KAFKA_BROKER: "kafka-broker:9092"
      TOPICS: ${KAFKA_TOPICS}
      PARTITIONS: ${KAFKA_NUM_PARTITIONS}
      REPLICATION_FACTOR: 1
    depends_on:
      kafka-broker:
        condition: service_healthy
    volumes:
      - ./kafka/scripts:/scripts:ro
    networks:
      - kafka-net

  # Apache Kafka Web UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8088:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:9092
      KAFKA_CLUSTERS_0_READONLY: "false"
    depends_on:
      - kafka-init
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "1g"
        reservations:
          cpus: "0.1"
          memory: "500m"

  # Apache Flink JobManager
  flink-jobmanager:
    image: shinushaju/bd25_project_f4_b-pyflink:1.18.1
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    expose:
      - "8081"
    command: jobmanager
    healthcheck:
      test: ["CMD", "curl", "-fs", "http://flink-jobmanager:8081/overview"]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      - kafka-init
    networks:
      - kafka-net
    volumes:
      - ./flink/jobs/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "2g"
        reservations:
          cpus: "0.5"
          memory: "1g"

  # Apache Flink TaskManager
  flink-taskmanager:
    image: shinushaju/bd25_project_f4_b-pyflink:1.18.1
    container_name: flink-taskmanager
    command: taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    networks:
      - kafka-net
    volumes:
      - ./flink/jobs/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
    environment:
      - |
        FLINK_PROPERTIES=
        taskmanager.numberOfTaskSlots: ${TASKMANAGER_TASK_SLOTS}
        parallelism.default: ${PARALLELISM}
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4g"
        reservations:
          cpus: "1"
          memory: "3g"

  # Apache Flink Init Container (Submit Flink Job)
  flink-init:
    image: shinushaju/bd25_project_f4_b-pyflink:1.18.1
    container_name: flink-init
    environment:
      PARALLELISM: ${PARALLELISM}
      CHECKPOINTING_MS: ${CHECKPOINTING_MS}
      PYTHON_DEPENDENCIES_PATH: ${PYTHON_DEPENDENCIES_PATH}
      KAFKA_CONNECTOR_JAR_FILE_PATH: ${KAFKA_CONNECTOR_JAR_FILE_PATH}
      KAFKA_BROKER_ADDRESS: "kafka-broker:9092"
      CONSUMER_GROUP_ID: ${CONSUMER_GROUP_ID}
      KAFKA_SOURCE_TOPICS: ${KAFKA_SOURCE_TOPICS}
      KAFKA_TAXI_PROCESSED_DATA_SINK_TOPIC: ${KAFKA_TAXI_PROCESSED_DATA_SINK_TOPIC}
      KAFKA_TAXI_VIOLATION_ALERTS_SINK_TOPIC: ${KAFKA_TAXI_VIOLATION_ALERTS_SINK_TOPIC}
      KAFKA_TAXI_FLEET_METRICS_SINK_TOPIC: ${KAFKA_TAXI_FLEET_METRICS_SINK_TOPIC}
      TRIP_INACTIVITY_TIMEOUT_IN_SECONDS: ${TRIP_INACTIVITY_TIMEOUT_IN_SECONDS}
      TRIP_EMIT_INTERVAL_IN_SECONDS: ${TRIP_EMIT_INTERVAL_IN_SECONDS}
      FORBIDDEN_CITY_LAT: ${FORBIDDEN_CITY_LAT}
      FORBIDDEN_CITY_LON: ${FORBIDDEN_CITY_LON}
      GEOFENCE_WARNING_KM: ${GEOFENCE_WARNING_KM}
      GEOFENCE_RANGE_KM: ${GEOFENCE_RANGE_KM}
      SPEED_THRESHOLD_KMPH: ${SPEED_THRESHOLD_KMPH}
    entrypoint: ["/bin/sh", "-c", "/opt/flink/scripts/submit-job.sh"]
    depends_on:
      - flink-taskmanager
    volumes:
      - ./utils:/opt/flink/utils
      - ./flink/scripts:/opt/flink/scripts
      - ./flink/jobs:/opt/flink/jobs
    networks:
      - kafka-net

  # Redis
  redis:
    image: redis:8-alpine
    container_name: redis
    ports:
      - "6379:6379"
    depends_on:
      - kafka-init
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "500m"
        reservations:
          cpus: "0.25"
          memory: "250m"

  # Kafka Redis Consumer
  kafka-redis-consumer:
    image: shinushaju/bd25_project_f4_b-kafka-redis-consumer:latest
    container_name: kafka-redis-consumer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:9092
      KAFKA_REDIS_CONSUMER_STARTUP_DELAY: ${KAFKA_REDIS_CONSUMER_STARTUP_DELAY}
      KAFKA_REDIS_TAXI_DATA_CONSUMER_TOPIC: ${KAFKA_REDIS_TAXI_DATA_CONSUMER_TOPIC}
      KAFKA_REDIS_TAXI_DATA_CONSUMER_GROUP: ${KAFKA_REDIS_TAXI_DATA_CONSUMER_GROUP}
      KAFKA_REDIS_TAXI_VIOLATION_ALERTS_CONSUMER_TOPIC: ${KAFKA_REDIS_TAXI_VIOLATION_ALERTS_CONSUMER_TOPIC}
      KAFKA_REDIS_TAXI_VIOLATION_ALERTS_CONSUMER_GROUP: ${KAFKA_REDIS_TAXI_VIOLATION_ALERTS_CONSUMER_GROUP}
      KAFKA_REDIS_TAXI_FLEET_METRICS_CONSUMER_TOPIC: ${KAFKA_REDIS_TAXI_FLEET_METRICS_CONSUMER_TOPIC}
      KAFKA_REDIS_TAXI_FLEET_METRICS_CONSUMER_GROUP: ${KAFKA_REDIS_TAXI_FLEET_METRICS_CONSUMER_GROUP}
      REDIS_HOST: redis
      REDIS_PORT: ${REDIS_PORT}
      REDIS_TAXI_VIOLATION_ALERTS_STREAM: ${REDIS_TAXI_VIOLATION_ALERTS_STREAM}
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./utils:/app/utils
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: "250m"
        reservations:
          cpus: "0.1"
          memory: "100m"

  # FastAPI Backend APIs
  fastapi-backend-apis:
    image: shinushaju/bd25_project_f4_b-fastapi-backend-apis:latest
    container_name: fastapi-backend-apis
    ports:
      - "8000:8000" 
    environment:
      REDIS_HOST: redis
      REDIS_PORT: ${REDIS_PORT}
      WEBSOCKET_INTERVAL_IN_SECONDS: ${WEBSOCKET_INTERVAL_IN_SECONDS}
      DATASET_SIZE_LIMIT: ${DATASET_SIZE_LIMIT}
      DATA_REPLAY_MODE: ${DATA_REPLAY_MODE}
      DATA_REPLAY_SPEED: ${DATA_REPLAY_SPEED}
      INFLUXDB_URL: http://influxdb:${INFLUXDB_PORT}
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_ORG: ${INFLUXDB_ORG}
    depends_on:
      - kafka-redis-consumer
    volumes:
      - ./utils:/app/utils
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "500m"
        reservations:
          cpus: "0.2"
          memory: "250m"

  # Dashboard UI
  dashboard-ui:
    image: shinushaju/bd25_project_f4_b-dashboard-ui:latest
    container_name: dashboard-ui
    ports:
      - "3000:3000"
    depends_on:
      - fastapi-backend-apis
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: "500m"
        reservations:
          cpus: "0.1"
          memory: "250m"

  # Kafka Producer
  kafka-producer:
    image: shinushaju/bd25_project_f4_b-kafka-producer:latest
    container_name: kafka-producer
    environment:
      KAFKA_BROKER_ADDRESS: kafka-broker:9092
      KAFKA_TOPIC: ${KAFKA_PRODUCER_TOPIC}
      DATASET_SIZE_LIMIT: ${DATASET_SIZE_LIMIT}
      DATA_REPLAY_MODE: ${DATA_REPLAY_MODE}
      DATA_REPLAY_SPEED: ${DATA_REPLAY_SPEED}
    depends_on:
      - dashboard-ui
    volumes:
      - ./data:/app/data
      - ./utils:/app/utils
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: "4g"
        reservations:
          cpus: "0.8"
          memory: "3g"

  # InfluxDB
  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - ${INFLUXDB_PORT}:${INFLUXDB_PORT}
    volumes:
      - ./utils:/app/utils
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USERNAME}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUXDB_ORG}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUXDB_BUCKET}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN}
      DOCKER_INFLUXDB_INIT_RETENTION: 0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://influxdb:${INFLUXDB_PORT}/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kafka-net
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: "3g"
        reservations:
          cpus: "0.5"
          memory: "1.5g"

  # Kafka InfluxDB Consumer
  kafka-influxdb-consumer:
    image: shinushaju/bd25_project_f4_b-kafka-influxdb-consumer:latest
    container_name: kafka-influxdb-consumer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka-broker:9092
      KAFKA_INFLUXDB_TAXI_DATA_CONSUMER_TOPIC: ${KAFKA_INFLUXDB_TAXI_DATA_CONSUMER_TOPIC}
      KAFKA_INFLUXDB_TAXI_DATA_CONSUMER_GROUP: ${KAFKA_INFLUXDB_TAXI_DATA_CONSUMER_GROUP}
      KAFKA_INFLUXDB_TAXI_VIOLATION_ALERTS_CONSUMER_TOPIC: ${KAFKA_INFLUXDB_TAXI_VIOLATION_ALERTS_CONSUMER_TOPIC}
      KAFKA_INFLUXDB_TAXI_VIOLATION_ALERTS_CONSUMER_GROUP: ${KAFKA_INFLUXDB_TAXI_VIOLATION_ALERTS_CONSUMER_GROUP}
      KAFKA_INFLUXDB_TAXI_FLEET_METRICS_CONSUMER_TOPIC: ${KAFKA_INFLUXDB_TAXI_FLEET_METRICS_CONSUMER_TOPIC}
      KAFKA_INFLUXDB_TAXI_FLEET_METRICS_CONSUMER_GROUP: ${KAFKA_INFLUXDB_TAXI_FLEET_METRICS_CONSUMER_GROUP}
      KAFKA_INFLUXDB_CONSUMER_STARTUP_DELAY: ${KAFKA_INFLUXDB_CONSUMER_STARTUP_DELAY}
      INFLUXDB_URL: http://influxdb:${INFLUXDB_PORT}
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_ORG: ${INFLUXDB_ORG}
    depends_on:
      kafka-broker:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    volumes:
      - ./utils:/app/utils
    networks:
     - kafka-net
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: "500m"
        reservations:
          cpus: "0.1"
          memory: "250m"

  # Prometheus
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./flink/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  #   networks:
  #     - kafka-net

networks:
  kafka-net:
    name: kafka-network
    driver: bridge
